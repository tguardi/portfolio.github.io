{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion & Preparation\n",
    "\n",
    "This notebook pulls Covid-19 data on the number of cases and deaths by state and merges it to Google mobility data.\n",
    "\n",
    "A file, **covid19_google_mobility_by_state.csv**, is saved after running the notebook and contains \n",
    "\n",
    "|Column | Description |\n",
    "|--------|--------|\n",
    "|`state` | State |\n",
    "|`date` | Date | \n",
    "|`retail_and_recreation` | Google Mobility: Percent change from base, retail and recreation |\n",
    "|`grocery_and_pharmacy` | Google Mobility: Percent change from base, grocery and pharmacy |\n",
    "|`parks` | Google Mobility: Percent change from base, parks |\n",
    "|`transit_stations` | Google Mobility: Percent change from base, transit stations |\n",
    "|`workplaces` | Google Mobility: Percent change from base, workplaces |\n",
    "|`residential` | Google Mobiity: Percent change from base, residential |\n",
    "|`pop` | State population (from Covid-19 deaths data) |\n",
    "|`deaths` | Number of deaths to date (from Covid-19 deaths data)|\n",
    "|`cases` | Number of confirmed cases to date (from Covid-19 confirmed cases data)|\n",
    "|`cases_per_capita` | Generated: Number of cases/population|\n",
    "|`deaths_per_capita` | Generated: Number of deaths/population|\n",
    "|`death_rate` | Generated: Number of deaths/number of cases|\n",
    "|`dcases` | Generated: Change in number of confirmed cases|\n",
    "|`ddeaths` | Generated: Change in number of deaths|\n",
    "\n",
    "\n",
    "### Data are pulled from the following links\n",
    "\n",
    "* Google Mobility: https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv\n",
    "* JH Cases: https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\n",
    "* JH Deaths: https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional variables from alternate sources to the state-level dataset:\n",
    "\n",
    "\n",
    "* Policy data  by state: https://github.com/KristenNocka/COVID-19-US-State-Policy-Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize']=(10, 5)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can move on to the mobility and covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cases = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "url_deaths = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "url_mobility = 'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Google Mobility Data\n",
    "\n",
    "A few notes on the Google Mobility data before we dive in. \n",
    "\n",
    "The file we pull can be found at https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv and contains mobility data for the following categories (variable names in parentheses):\n",
    "\n",
    "* Retail and recreation (`retail_and_recreation`)\n",
    "* Grocery and pharmacy (`grocery_and_pharmacy`)\n",
    "* Parks (`parks`)\n",
    "* Transit stations (`transit_stations`)\n",
    "* Workplaces (`workplaces`)\n",
    "* Residential (`residential`)\n",
    "\n",
    "We are going to create three separate data sets:\n",
    "\n",
    "1. National level\n",
    "2. State level\n",
    "3. County level\n",
    "\n",
    "The raw data is at the global level - we trim it down to just observations for the United States. After doing so, the variables `sub_region_1` and `sub_region_2` are *state* and *county*, respectively. \n",
    "\n",
    "- Observations missing **both** `sub_region_1` **and** `sub_region_2` are for the United States as a whole\n",
    "- Observations missing `sub_region_2` and **NOT** `sub_region_1` are at the state (and DC) level\n",
    "- Observations with **both** `sub_region_1` and `sub_region_2` are at the county level\n",
    "\n",
    "We will keep this in mind as we create the three data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the full goog-mob file.\n",
    "google_mobility = pd.read_csv(url_mobility)\n",
    "\n",
    "# Trim to the US and rename columns\n",
    "# 6/16 added drop fips and iso\n",
    "google_mobility = google_mobility[google_mobility['country_region_code']=='US'].drop(columns = {'country_region_code', 'country_region', 'iso_3166_2_code','census_fips_code'})\n",
    "# google_mobility = google_mobility[google_mobility['country_region_code']=='US'].drop(columns = {'country_region_code', 'country_region','iso_3166_2_code'})\n",
    "\n",
    "google_mobility = google_mobility.rename(columns = {\n",
    "    'retail_and_recreation_percent_change_from_baseline': 'retail_and_recreation', \n",
    "    'grocery_and_pharmacy_percent_change_from_baseline': 'grocery_and_pharmacy',\n",
    "    'parks_percent_change_from_baseline': 'parks',\n",
    "    'transit_stations_percent_change_from_baseline': 'transit_stations',\n",
    "    'workplaces_percent_change_from_baseline': 'workplaces',\n",
    "    'residential_percent_change_from_baseline': 'residential',\n",
    "    'sub_region_1': 'state',\n",
    "    'sub_region_2': 'county'})\n",
    "\n",
    "# Create US-level data frame\n",
    "google_mobility_us = google_mobility[google_mobility['state'].isna() & google_mobility['county'].isna()].drop(columns={'state', 'county'})\n",
    "google_mobility_us['date'] = pd.to_datetime(google_mobility_us['date'], format=\"%Y-%m-%d\")\n",
    "google_mobility_us = google_mobility_us.set_index('date')\n",
    "\n",
    "# Create state-level data frame\n",
    "google_mobility_states = google_mobility[google_mobility['county'].isna() & ~google_mobility['state'].isna()].drop(columns={'county'})\n",
    "google_mobility_states['date'] = pd.to_datetime(google_mobility_states['date'], format=\"%Y-%m-%d\")\n",
    "state_date = google_mobility_states[['state', 'date']]\n",
    "google_mobility_states = google_mobility_states.set_index(pd.MultiIndex.from_frame(state_date))\n",
    "google_mobility_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Johns Hopkins Data on Confirmed Cases\n",
    "\n",
    "For now this is just at the level of the state - I am going to do it by county next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV from GitHub repo\n",
    "cases = pd.read_csv(url_cases)\n",
    "\n",
    "# Drop stuff we don't need and trim to the 50 states and DC\n",
    "cases = cases.rename(columns = {'Admin2': 'county', 'Province_State': 'state'})\n",
    "cases = cases.drop(columns={'county', 'iso2', 'iso3', 'code3', 'Country_Region', 'Lat', 'Long_', 'Combined_Key', 'UID', 'FIPS'})\n",
    "drop_states = ['Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands', 'Guam', 'American Samoa', 'Diamond Princess', 'Grand Princess']\n",
    "for st in drop_states:\n",
    "    cases = cases[cases['state']!=st]\n",
    "\n",
    "# Reshape to long format\n",
    "cases = cases.melt(id_vars = 'state', var_name = 'date', value_name='cases').sort_values(by = ['state', 'date'])\n",
    "cases = cases.groupby(['state', 'date']).sum().reset_index()\n",
    "\n",
    "# Set the date variable to datetime and sort the data frame\n",
    "cases['date'] = pd.to_datetime(cases['date'], format=\"%m/%d/%y\")\n",
    "cases = cases.sort_values(['state', 'date'])\n",
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Johns Hopkins Data on Deaths\n",
    "\n",
    "Again, just at the state-level...for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV from GitHub repo\n",
    "deaths = pd.read_csv(url_deaths)\n",
    "\n",
    "# Drop stuff we don't need and trim to the 50 states and DC\n",
    "deaths = deaths.drop(columns={'iso2', 'iso3', 'code3', 'Country_Region', 'Lat', 'Long_', 'Combined_Key', 'UID', 'FIPS'})\n",
    "drop_states = ['Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands', 'Guam', 'American Samoa', 'Diamond Princess', 'Grand Princess']\n",
    "for st in drop_states:\n",
    "    deaths = deaths[deaths['Province_State']!=st]\n",
    "\n",
    "# Rename some variables and make sure the states look ok\n",
    "deaths = deaths.rename(columns = {'Admin2': 'county', 'Province_State': 'state', 'Population': 'pop'})\n",
    "deaths['state'].value_counts()\n",
    "deaths = deaths.sort_values('state')\n",
    "deaths = deaths.drop(columns='county')\n",
    "\n",
    "# Reshape to long format\n",
    "deaths = deaths.melt(id_vars = {'state', 'pop'}, var_name = 'date', value_name='deaths').sort_values(by = ['state', 'date'])\n",
    "deaths = deaths.groupby(['state', 'date']).sum().reset_index()\n",
    "\n",
    "# Set the date variable to datetime and sort the data frame\n",
    "deaths['date'] = pd.to_datetime(deaths['date'], format=\"%m/%d/%y\")\n",
    "deaths = deaths.sort_values(['state', 'date'])\n",
    "deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Confirmed Cases and Deaths Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and reset the index\n",
    "covid19 = deaths.merge(cases)\n",
    "covid19 = covid19.set_index(pd.MultiIndex.from_frame(covid19[['state', 'date']]))\n",
    "\n",
    "# Drop state and date variables (they're in the index)\n",
    "covid19 = covid19.drop(columns={'state', 'date'})\n",
    "\n",
    "# Daily cases_per_capita\n",
    "# covid19['cases_per_capita'] = covid19['cases'].divide(covid19['pop'])\n",
    "# covid19['cases_per_capita'] = covid19['cases'].diff()\n",
    "covid19['cases_per_capita'] = covid19['cases'].divide(covid19['pop'])\n",
    "covid19['cases_per_capita'] = covid19['cases_per_capita'].diff()\n",
    "\n",
    "# Generate deaths per capita\n",
    "covid19['deaths_per_capita'] = covid19['deaths'].divide(covid19['pop'])\n",
    "\n",
    "# And a \"death-rate\" as the number of deaths/confirmed cases\n",
    "covid19['death_rate'] = covid19['deaths'].divide(covid19['cases'])\n",
    "\n",
    "# Change in number of cases\n",
    "covid19['dcases'] = covid19['cases'].diff()\n",
    "\n",
    "# Change in number of deaths\n",
    "covid19['ddeaths'] = covid19['deaths'].diff()\n",
    "covid19.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Covid-19 Data with Google Mobility Data\n",
    "\n",
    "Then, write the data frame to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data frames on their indexes, which we set above\n",
    "df = google_mobility_states.merge(covid19, left_on=google_mobility_states.index.to_numpy(), right_on=covid19.index.to_numpy()).reset_index()\n",
    "\n",
    "# Now reset the index\n",
    "df = df.set_index(pd.MultiIndex.from_frame(df[['state', 'date']]))\n",
    "\n",
    "# Drop stuff we don't need \n",
    "df = df.drop(columns={'index', 'key_0', 'state', 'date', 'metro_area'})\n",
    "df.to_csv('covid19_google_mobility_by_state.csv')\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "## Why we are focusing on state level data\n",
    "- America in Covid is like 50 different petri dishes, no 2 states are alike in policy or results\n",
    "- Initial assumption is State level policy is driving mobility so we begin our analysis at the state level rather than country or county\n",
    "- First step is to find states that have seen a change since the economy has \"reopened\"\n",
    "- We begin by examining some moving averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting was easier with this change\n",
    "df1 = df.reset_index(level=['state','date'])\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.state = df1.state.astype(str)\n",
    "df1.cases = df1.dcases.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df1.groupby(by=['state','dcases'])\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most recent date data fram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_date = df1['date'].max()\n",
    "df_latest = df1[df1['date'] == recent_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventually we can use this framework for a webapp, need plots first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas for data management\n",
    "# import pandas as pd\n",
    "\n",
    "# # os methods for manipulating paths\n",
    "# from os.path import dirname, join\n",
    "\n",
    "# # Bokeh basics \n",
    "# from bokeh.io import curdoc\n",
    "# from bokeh.models.widgets import Tabs\n",
    "\n",
    "\n",
    "# # Each tab is drawn by one script\n",
    "# # from scripts.histogram import histogram_tab\n",
    "# # from scripts.density import density_tab\n",
    "# # from scripts.table import table_tab\n",
    "# # from scripts.draw_map import map_tab\n",
    "# # from scripts.routes import route_tab\n",
    "\n",
    "# # Using included state data from Bokeh for map\n",
    "# from bokeh.sampledata.us_states import data as states\n",
    "\n",
    "# # Read data into dataframes\n",
    "# # flights = pd.read_csv(join(dirname(__file__), 'data', 'flights.csv'), \n",
    "# # \t                                          index_col=0).dropna()\n",
    "# daily_cases = df_latest['dcases']\n",
    "# overall_cases = df_latest['cases']\n",
    "\n",
    "# # Formatted Flight Delay Data for map\n",
    "# # map_data = pd.read_csv(join(dirname(__file__), 'data', 'flights_map.csv'),\n",
    "# #                             header=[0,1], index_col=0)\n",
    "\n",
    "# # Create each of the tabs\n",
    "# # tab1 = histogram_tab(daily_cases)\n",
    "# # tab2 = density_tab(daily_cases)\n",
    "# # tab3 = table_tab(daily_cases)\n",
    "# # tab4 = map_tab(daily_cases, states)\n",
    "# # tab5 = route_tb(daily_cases)\n",
    "\n",
    "# # Put all the tabs into one application\n",
    "# tabs = Tabs(tabs = [tab1, tab2, tab3, tab4, tab5])\n",
    "\n",
    "# # Put the tabs in the current document for display\n",
    "# curdoc().add_root(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.autompg import autompg_clean as df\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "group = df_latest.groupby(by=['state','dcases'])\n",
    "source = ColumnDataSource(group)\n",
    "\n",
    "p = figure(plot_width=800, plot_height=300, title=\"Daily_Cases_by_State\",\n",
    "           x_range=group, toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.axis_label = \"States grouped by # Cases\"\n",
    "p.xaxis.major_label_orientation = 1.2\n",
    "\n",
    "index_cmap = factor_cmap('states', palette=['#2b83ba', '#abdda4', '#ffffbf', '#fdae61', '#d7191c'], \n",
    "                         factors=sorted(df_latest.state.unique()), end=1)\n",
    "\n",
    "p.vbar(x='states', top='cases', width=1, source=source,\n",
    "       line_color=\"white\", fill_color=index_cmap, \n",
    "       hover_line_color=\"darkgrey\", hover_fill_color=index_cmap)\n",
    "\n",
    "p.add_tools(HoverTool(tooltips=[(\"Cases\", \"@dcases\")]))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobility EDA\n",
    "## Charting mobility and daily cases\n",
    "### Starting with Falling Cases states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to speed up plotting 10 different states\n",
    "def plot_mobility_cases(state_name):\n",
    "    \"\"\"\n",
    "    For given state or states, returns moblity charts and new daily cases chart\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title('Moblity ' + state_name)\n",
    "    df.loc[state_name]['retail_and_recreation'].plot(label='RetailRec')\n",
    "    df.loc[state_name]['residential'].plot(label='Residential')\n",
    "    df.loc[state_name]['workplaces'].plot(label='Workplace')\n",
    "    df.loc[state_name]['transit_stations'].plot(label='Transit')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Daily cases ' + state_name)\n",
    "    df.loc[state_name]['dcases'].plot(label='dcases')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All States in this group surged early and peaked\n",
    "- Pennsylvania stands out on the mobility measures but all have seen an upward trend, which makes sense given how far the mobility measures fell. A month from now will be interesting to see if trends return to or above the baseline (remember it was set in Jan and Feb)\n",
    "- Mobility at the lows around Mid April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"date\", y=\"retail_and_recreation\", data=df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The \"Falling\"\n",
    "plot_mobility_cases('Illinois')\n",
    "plot_mobility_cases('New York')\n",
    "plot_mobility_cases('New Jersey')\n",
    "plot_mobility_cases('Pennsylvania')\n",
    "plot_mobility_cases('Massachusetts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States that have seen a recent increase in the rate of new cases\n",
    "- Texas, Arizona and North Carolina have seen notable rises across the mobility measures\n",
    "- California and Florida mobility is notably lower than the others in this group, both had early spikes in cases\n",
    "- Texas, Arizona and North Carolina were relatively spared at the start of the pandemic, perhaps leading to false confidence\n",
    "- The troughs in the mobility measures were notably shorter for some of the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mobility_cases('Texas')\n",
    "plot_mobility_cases('Arizona')\n",
    "plot_mobility_cases('North Carolina')\n",
    "plot_mobility_cases('Florida')\n",
    "plot_mobility_cases('California')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid Data EDA\n",
    "\n",
    "### Creating 7 day moving average\n",
    "\n",
    "### What states are seeing the biggest change in the number of daily cases? A measure often cited in the media is the 7 day moving average. It smooths out some of the daily fluctuations and allows us to look at longer chunks of time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up Moving average and moving average per capita for 7 days\n",
    "df1['MovingAvg7'] = df1.loc[:,'dcases'].rolling(window=7).mean()\n",
    "df1['MovingAvg7_percap'] = df1.loc[:,'cases_per_capita'].rolling(window=7).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 2 date \"snapshots\"\n",
    "- for later use in analyzing month to month differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest = df1[df1['date']=='2020-08-07']\n",
    "df_last_month = df1[df1['date']=='2020-07-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizing 7 Day moving average of new cases for each state\n",
    "- population size is obviously a big driver, but I see some states that aren't the highest pop as well\n",
    "- let's dig deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = df_latest.sort_values('MovingAvg7', axis=0, ascending=False)['MovingAvg7']\n",
    "y = df_latest.sort_values('MovingAvg7', axis=0, ascending=False)['state']\n",
    "plt.figure(figsize=(8, 15))\n",
    "sns.barplot(x=x, y=y, orient='h')\n",
    "#plt.xlim(0,0.3)  fix population on x access?\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('7 Day Moving Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average per capita\n",
    "- Making sure we're not seeing any population effects dominate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = df_latest.sort_values('MovingAvg7_percap', axis=0, ascending=False)['MovingAvg7_percap']\n",
    "y = df_latest.sort_values('MovingAvg7_percap', axis=0, ascending=False)['state']\n",
    "\n",
    "plt.figure(figsize=(8, 15))\n",
    "sns.barplot(x=x, y=y, orient='h')\n",
    "#plt.xlim(0,0.3)  fix population on x access?\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('7 Day Moving Average Per Capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting 7 day MA for Illinois, Texas, NY and California\n",
    "- Illinois, New York, Texas and California are all high on the 7 day MA list, most likely because they were high on overall number of cases due to population\n",
    "- Let's look at 7 day moving average over time for a few states\n",
    "- Illinois and NYC both turned lower\n",
    "- We're not capturing states that have a diminishing number of cases with our above analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('IL 7 Day MA')\n",
    "df1[df1['state']=='Illinois']['MovingAvg7'].plot()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('TX 7 Day MA')\n",
    "df1[df1['state']=='Texas']['MovingAvg7'].plot()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('NY 7 Day MA')\n",
    "df1[df1['state']=='New York']['MovingAvg7'].plot()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('CA 7 Day MA')\n",
    "df1[df1['state']=='California']['MovingAvg7'].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases per day: 7 day MA vs Last Month\n",
    "- let's look at a \"snapshot\" one month ago versus today to assess which states are seeing a concerning rise and a reassuring fall in new daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest = df1[df1['date']=='2020-08-07']\n",
    "df_last_month = df1[df1['date']=='2020-06-27']\n",
    "\n",
    "df_latest['Month_MA_pc'] = df_latest.loc[:,'MovingAvg7_percap'].values - df_last_month.loc[:,'MovingAvg7_percap'].values\n",
    "df_latest['Month_MA'] = df_latest.loc[:,'MovingAvg7'].values - df_last_month.loc[:,'MovingAvg7'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Month to Month moving average\n",
    "- We use the dates 5/12 and 6/12 and we take a snapshot of the 7 day moving average\n",
    "- What can we tell about the states that are increasing?\n",
    "- Can we find similar policies in common across groups of states?\n",
    "- What about the states that have seen improvement, are there similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = df_latest.sort_values('Month_MA', axis=0, ascending=False)['Month_MA']\n",
    "y = df_latest.sort_values('Month_MA', axis=0, ascending=False)['state']\n",
    "\n",
    "plt.figure(figsize=(8, 15))\n",
    "sns.barplot(x=x, y=y, orient='h')\n",
    "#plt.xlim(0,0.3)  fix population on x access?\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Month over month change in 7 Day MA on 6/22 vs 5/22')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per cap MA's - controlling for population\n",
    "- Some smaller states have a worrying rise\n",
    "- Large population states were hit hard early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = df_latest.sort_values('Month_MA_pc', axis=0, ascending=False)['Month_MA_pc']\n",
    "y = df_latest.sort_values('Month_MA_pc', axis=0, ascending=False)['state']\n",
    "\n",
    "plt.figure(figsize=(8, 15))\n",
    "sns.barplot(x=x, y=y, orient='h')\n",
    "#plt.xlim(0,0.3)  fix population on x access?\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Month over month change in 7 Day MA per capita on 6/12 vs 5/12')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm = df1[['state','date','MovingAvg7','retail_and_recreation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL = df_hmm[df_hmm['state'] == 'Illinois']\n",
    "\n",
    "df_hmm_IL['MovingAvg7'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL['diff_retail_and_recreation'] = df_hmm_IL['retail_and_recreation'].diff()\n",
    "df_hmm_IL['diff_retail_and_recreation'] = df_hmm_IL['diff_retail_and_recreation'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL['MA7'] = df_hmm_IL['MovingAvg7'].apply(lambda x: 1 if x >= 1000 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL['diff_retail_and_recreation'] = df_hmm_IL['diff_retail_and_recreation'].fillna(0)\n",
    "df_hmm_IL['MA7'] = df_hmm_IL['MA7'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hmm_IL.to_csv('df_hmm_IL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    " \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            # Matrix Computation Steps\n",
    "            #                  ((1x2) . (1x2))      *     (1)\n",
    "            #                        (1)            *     (1)\n",
    "            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]\n",
    " \n",
    "    return alpha\n",
    " \n",
    " \n",
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])\n",
    " \n",
    "    return beta\n",
    " \n",
    " \n",
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    " \n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    " \n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    " \n",
    "V = df['dcases'].values\n",
    " \n",
    "# Transition Probabilities\n",
    "a = np.ones((2, 2))\n",
    "a = a / np.sum(a, axis=1)\n",
    " \n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    " \n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    " \n",
    "print(baum_welch(V, a, b, initial_distribution, n_iter=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
